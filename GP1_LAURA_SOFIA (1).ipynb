{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LziSPu_SxX9q",
        "outputId": "1771040a-a8a1-40f2-8d2d-097bff038b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install gradio --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "# Opciones con emojis\n",
        "opciones = {\n",
        "    \"Piedra\": \"🪨\",\n",
        "    \"Papel\": \"📄\",\n",
        "    \"Tijera\": \"✂️\",\n",
        "    \"Lagarto\": \"🦎\",\n",
        "    \"Spock\": \"🖖\",\n",
        "    \"Pistola\": \"🔫\"\n",
        "}\n",
        "\n",
        "# Reglas del juego extendido con Pistola\n",
        "def determinar_ganador(jugador1, jugador2):\n",
        "    if jugador1 == jugador2:\n",
        "        return f\"🤝 ¡Empate!\\n\\nTú elegiste {opciones[jugador1]} ({jugador1})\\nLa computadora eligió {opciones[jugador2]} ({jugador2})\"\n",
        "\n",
        "    gana_jugador1 = (\n",
        "        # Piedra gana a Tijera y Lagarto\n",
        "        (jugador1 == \"Piedra\" and (jugador2 == \"Tijera\" or jugador2 == \"Lagarto\")) or\n",
        "        # Papel gana a Piedra y Spock y Pistola\n",
        "        (jugador1 == \"Papel\" and (jugador2 == \"Piedra\" or jugador2 == \"Spock\" or jugador2 == \"Pistola\")) or\n",
        "        # Tijera gana a Papel y Lagarto\n",
        "        (jugador1 == \"Tijera\" and (jugador2 == \"Papel\" or jugador2 == \"Lagarto\")) or\n",
        "        # Lagarto gana a Spock y Papel\n",
        "        (jugador1 == \"Lagarto\" and (jugador2 == \"Spock\" or jugador2 == \"Papel\")) or\n",
        "        # Spock gana a Tijera y Piedra\n",
        "        (jugador1 == \"Spock\" and (jugador2 == \"Tijera\" or jugador2 == \"Piedra\")) or\n",
        "        # Pistola gana a Piedra, Tijera y Lagarto\n",
        "        (jugador1 == \"Pistola\" and (jugador2 == \"Piedra\" or jugador2 == \"Tijera\" or jugador2 == \"Lagarto\"))\n",
        "    )\n",
        "\n",
        "    if gana_jugador1:\n",
        "        return f\"🎉 ¡Tú ganas!\\n\\nTú elegiste {opciones[jugador1]} ({jugador1})\\nLa computadora eligió {opciones[jugador2]} ({jugador2})\"\n",
        "    else:\n",
        "        return f\"💻 La computadora gana\\n\\nTú elegiste {opciones[jugador1]} ({jugador1})\\nLa computadora eligió {opciones[jugador2]} ({jugador2})\"\n",
        "\n",
        "def jugar(eleccion_jugador):\n",
        "    eleccion_computadora = random.choice(list(opciones.keys()))\n",
        "    resultado = determinar_ganador(eleccion_jugador, eleccion_computadora)\n",
        "    return resultado\n",
        "\n",
        "gr.Interface(\n",
        "    fn=jugar,\n",
        "    inputs=gr.Radio(choices=list(opciones.keys()), label=\"Elige tu jugada\", info=\"¡Selecciona una opción!\"),\n",
        "    outputs=gr.Textbox(label=\"Resultado\"),\n",
        "    title=\"🪨📄✂️🦎🖖🔫 Piedra, Papel, Tijera, Lagarto, Spock y Pistola\",\n",
        "    description=\"Juega contra la computadora. ¡Elige tu opción y mira quién gana!\"\n",
        ").launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "0lrzrofZxfax",
        "outputId": "8585e44f-2c09-4135-a35e-ea0010a5c68a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://22afeb1eb6b36c032c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://22afeb1eb6b36c032c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}